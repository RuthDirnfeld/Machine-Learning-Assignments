{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from scipy.stats import pearsonr\n",
    "import itertools\n",
    "np.warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn import neighbors\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ISLR/data/Smarket.csv',index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "1. 'Year' 2. 'Lag1' 3. 'Lag2' 4. 'Lag3' 5. 'Lag4' 6. 'Lag5' 7. 'Volume' 8. 'Today' 9. 'Direction' "
     ]
    }
   ],
   "source": [
    "r, c = df.shape\n",
    "print(c)\n",
    "for a, b in enumerate(df, 1):\n",
    "    list = \"\".join('{}. \\'{}\\''.format(a, b))\n",
    "    print (list, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Today</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1250.00000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2003.016000</td>\n",
       "      <td>0.003834</td>\n",
       "      <td>0.003919</td>\n",
       "      <td>0.001716</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.00561</td>\n",
       "      <td>1.478305</td>\n",
       "      <td>0.003138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.409018</td>\n",
       "      <td>1.136299</td>\n",
       "      <td>1.136280</td>\n",
       "      <td>1.138703</td>\n",
       "      <td>1.138774</td>\n",
       "      <td>1.14755</td>\n",
       "      <td>0.360357</td>\n",
       "      <td>1.136334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2001.000000</td>\n",
       "      <td>-4.922000</td>\n",
       "      <td>-4.922000</td>\n",
       "      <td>-4.922000</td>\n",
       "      <td>-4.922000</td>\n",
       "      <td>-4.92200</td>\n",
       "      <td>0.356070</td>\n",
       "      <td>-4.922000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2002.000000</td>\n",
       "      <td>-0.639500</td>\n",
       "      <td>-0.639500</td>\n",
       "      <td>-0.640000</td>\n",
       "      <td>-0.640000</td>\n",
       "      <td>-0.64000</td>\n",
       "      <td>1.257400</td>\n",
       "      <td>-0.639500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2003.000000</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.038500</td>\n",
       "      <td>0.038500</td>\n",
       "      <td>0.03850</td>\n",
       "      <td>1.422950</td>\n",
       "      <td>0.038500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2004.000000</td>\n",
       "      <td>0.596750</td>\n",
       "      <td>0.596750</td>\n",
       "      <td>0.596750</td>\n",
       "      <td>0.596750</td>\n",
       "      <td>0.59700</td>\n",
       "      <td>1.641675</td>\n",
       "      <td>0.596750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2005.000000</td>\n",
       "      <td>5.733000</td>\n",
       "      <td>5.733000</td>\n",
       "      <td>5.733000</td>\n",
       "      <td>5.733000</td>\n",
       "      <td>5.73300</td>\n",
       "      <td>3.152470</td>\n",
       "      <td>5.733000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Year         Lag1         Lag2         Lag3         Lag4  \\\n",
       "count  1250.000000  1250.000000  1250.000000  1250.000000  1250.000000   \n",
       "mean   2003.016000     0.003834     0.003919     0.001716     0.001636   \n",
       "std       1.409018     1.136299     1.136280     1.138703     1.138774   \n",
       "min    2001.000000    -4.922000    -4.922000    -4.922000    -4.922000   \n",
       "25%    2002.000000    -0.639500    -0.639500    -0.640000    -0.640000   \n",
       "50%    2003.000000     0.039000     0.039000     0.038500     0.038500   \n",
       "75%    2004.000000     0.596750     0.596750     0.596750     0.596750   \n",
       "max    2005.000000     5.733000     5.733000     5.733000     5.733000   \n",
       "\n",
       "             Lag5       Volume        Today  \n",
       "count  1250.00000  1250.000000  1250.000000  \n",
       "mean      0.00561     1.478305     0.003138  \n",
       "std       1.14755     0.360357     1.136334  \n",
       "min      -4.92200     0.356070    -4.922000  \n",
       "25%      -0.64000     1.257400    -0.639500  \n",
       "50%       0.03850     1.422950     0.038500  \n",
       "75%       0.59700     1.641675     0.596750  \n",
       "max       5.73300     3.152470     5.733000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Up      648\n",
      "Down    602\n",
      "Name: Direction, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['Direction'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1250"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Today</th>\n",
       "      <th>Direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>-1.055</td>\n",
       "      <td>5.010</td>\n",
       "      <td>1.19130</td>\n",
       "      <td>0.959</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>-1.055</td>\n",
       "      <td>1.29650</td>\n",
       "      <td>1.032</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>1.41120</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>1.27600</td>\n",
       "      <td>0.614</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2001</td>\n",
       "      <td>0.614</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>1.20570</td>\n",
       "      <td>0.213</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>2005</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.252</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.584</td>\n",
       "      <td>-0.285</td>\n",
       "      <td>1.88850</td>\n",
       "      <td>0.043</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>2005</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.252</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.584</td>\n",
       "      <td>1.28581</td>\n",
       "      <td>-0.955</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>2005</td>\n",
       "      <td>-0.955</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.252</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>1.54047</td>\n",
       "      <td>0.130</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>2005</td>\n",
       "      <td>0.130</td>\n",
       "      <td>-0.955</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.252</td>\n",
       "      <td>1.42236</td>\n",
       "      <td>-0.298</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>2005</td>\n",
       "      <td>-0.298</td>\n",
       "      <td>0.130</td>\n",
       "      <td>-0.955</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.422</td>\n",
       "      <td>1.38254</td>\n",
       "      <td>-0.489</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1250 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year   Lag1   Lag2   Lag3   Lag4   Lag5   Volume  Today Direction\n",
       "1     2001  0.381 -0.192 -2.624 -1.055  5.010  1.19130  0.959        Up\n",
       "2     2001  0.959  0.381 -0.192 -2.624 -1.055  1.29650  1.032        Up\n",
       "3     2001  1.032  0.959  0.381 -0.192 -2.624  1.41120 -0.623      Down\n",
       "4     2001 -0.623  1.032  0.959  0.381 -0.192  1.27600  0.614        Up\n",
       "5     2001  0.614 -0.623  1.032  0.959  0.381  1.20570  0.213        Up\n",
       "...    ...    ...    ...    ...    ...    ...      ...    ...       ...\n",
       "1246  2005  0.422  0.252 -0.024 -0.584 -0.285  1.88850  0.043        Up\n",
       "1247  2005  0.043  0.422  0.252 -0.024 -0.584  1.28581 -0.955      Down\n",
       "1248  2005 -0.955  0.043  0.422  0.252 -0.024  1.54047  0.130        Up\n",
       "1249  2005  0.130 -0.955  0.043  0.422  0.252  1.42236 -0.298      Down\n",
       "1250  2005 -0.298  0.130 -0.955  0.043  0.422  1.38254 -0.489      Down\n",
       "\n",
       "[1250 rows x 9 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Year</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Today</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lag1</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <td>0.030</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volume</th>\n",
       "      <td>0.041</td>\n",
       "      <td>0.539</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag2</th>\n",
       "      <td>-0.026</td>\n",
       "      <td>0.031</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag5</th>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>-0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag4</th>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag3</th>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Today</th>\n",
       "      <td>-0.026</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Lag1   Year  Volume   Lag2   Lag5   Lag4   Lag3  Today\n",
       "Lag1    1.000  0.030   0.041 -0.026 -0.006 -0.003 -0.011 -0.026\n",
       "Year    0.030  1.000   0.539  0.031  0.030  0.036  0.033  0.030\n",
       "Volume  0.041  0.539   1.000 -0.043 -0.022 -0.048 -0.042  0.015\n",
       "Lag2   -0.026  0.031  -0.043  1.000 -0.004 -0.011 -0.026 -0.010\n",
       "Lag5   -0.006  0.030  -0.022 -0.004  1.000 -0.027 -0.019 -0.035\n",
       "Lag4   -0.003  0.036  -0.048 -0.011 -0.027  1.000 -0.024 -0.007\n",
       "Lag3   -0.011  0.033  -0.042 -0.026 -0.019 -0.024  1.000 -0.002\n",
       "Today  -0.026  0.030   0.015 -0.010 -0.035 -0.007 -0.002  1.000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Lag1', 'Year', 'Volume', 'Lag2', 'Lag5', 'Lag4', 'Lag3', 'Today']].corr().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Year</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Today</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lag1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.2941</td>\n",
       "      <td>0.1483</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.8411</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.7028</td>\n",
       "      <td>0.3555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <td>0.2941</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2797</td>\n",
       "      <td>0.2926</td>\n",
       "      <td>0.2073</td>\n",
       "      <td>0.2409</td>\n",
       "      <td>0.2877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volume</th>\n",
       "      <td>0.1483</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1253</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.0871</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>0.6063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag2</th>\n",
       "      <td>0.353</td>\n",
       "      <td>0.2797</td>\n",
       "      <td>0.1253</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.7015</td>\n",
       "      <td>0.3603</td>\n",
       "      <td>0.7173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag5</th>\n",
       "      <td>0.8411</td>\n",
       "      <td>0.2926</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3387</td>\n",
       "      <td>0.5065</td>\n",
       "      <td>0.2181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag4</th>\n",
       "      <td>0.916</td>\n",
       "      <td>0.2073</td>\n",
       "      <td>0.0871</td>\n",
       "      <td>0.7015</td>\n",
       "      <td>0.3387</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3955</td>\n",
       "      <td>0.8075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag3</th>\n",
       "      <td>0.7028</td>\n",
       "      <td>0.2409</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>0.3603</td>\n",
       "      <td>0.5065</td>\n",
       "      <td>0.3955</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Today</th>\n",
       "      <td>0.3555</td>\n",
       "      <td>0.2877</td>\n",
       "      <td>0.6063</td>\n",
       "      <td>0.7173</td>\n",
       "      <td>0.2181</td>\n",
       "      <td>0.8075</td>\n",
       "      <td>0.9311</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Lag1    Year  Volume    Lag2    Lag5    Lag4    Lag3   Today\n",
       "Lag1         0  0.2941  0.1483   0.353  0.8411   0.916  0.7028  0.3555\n",
       "Year    0.2941       0       0  0.2797  0.2926  0.2073  0.2409  0.2877\n",
       "Volume  0.1483       0       0  0.1253   0.437  0.0871  0.1394  0.6063\n",
       "Lag2     0.353  0.2797  0.1253       0     0.9  0.7015  0.3603  0.7173\n",
       "Lag5    0.8411  0.2926   0.437     0.9       0  0.3387  0.5065  0.2181\n",
       "Lag4     0.916  0.2073  0.0871  0.7015  0.3387       0  0.3955  0.8075\n",
       "Lag3    0.7028  0.2409  0.1394  0.3603  0.5065  0.3955       0  0.9311\n",
       "Today   0.3555  0.2877  0.6063  0.7173  0.2181  0.8075  0.9311       0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_pvalues(df):\n",
    "    df = df.dropna()._get_numeric_data()\n",
    "    dfcol = pd.DataFrame(columns=df.columns)\n",
    "    pval = dfcol.transpose().join(dfcol, how='outer')\n",
    "    for r in df.columns:\n",
    "        for c in df.columns:\n",
    "            pval[r][c] = round(pearsonr(df[r], df[c])[1], 4)\n",
    "    return pval\n",
    "\n",
    "calc_pvalues(df[['Lag1', 'Year', 'Volume', 'Lag2', 'Lag5', 'Lag4', 'Lag3', 'Today']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow0_col0 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow0_col1 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow0_col2 {\n",
       "            background-color:  #5470de;\n",
       "            color:  #000000;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow0_col3 {\n",
       "            background-color:  #3d50c3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow0_col4 {\n",
       "            background-color:  #3f53c6;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow0_col5 {\n",
       "            background-color:  #4961d2;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow0_col6 {\n",
       "            background-color:  #4358cb;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow0_col7 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow1_col0 {\n",
       "            background-color:  #4b64d5;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow1_col1 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow1_col2 {\n",
       "            background-color:  #ebd3c6;\n",
       "            color:  #000000;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow1_col3 {\n",
       "            background-color:  #4f69d9;\n",
       "            color:  #000000;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow1_col4 {\n",
       "            background-color:  #4b64d5;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow1_col5 {\n",
       "            background-color:  #5470de;\n",
       "            color:  #000000;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow1_col6 {\n",
       "            background-color:  #4f69d9;\n",
       "            color:  #000000;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow1_col7 {\n",
       "            background-color:  #4b64d5;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow2_col0 {\n",
       "            background-color:  #4f69d9;\n",
       "            color:  #000000;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow2_col1 {\n",
       "            background-color:  #e3d9d3;\n",
       "            color:  #000000;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow2_col2 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow2_col3 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow2_col4 {\n",
       "            background-color:  #3d50c3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow2_col5 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow2_col6 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow2_col7 {\n",
       "            background-color:  #455cce;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow3_col0 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow3_col1 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow3_col2 {\n",
       "            background-color:  #3d50c3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow3_col3 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow3_col4 {\n",
       "            background-color:  #4358cb;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow3_col5 {\n",
       "            background-color:  #455cce;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow3_col6 {\n",
       "            background-color:  #3d50c3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow3_col7 {\n",
       "            background-color:  #3f53c6;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow4_col0 {\n",
       "            background-color:  #3f53c6;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow4_col1 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow4_col2 {\n",
       "            background-color:  #4358cb;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow4_col3 {\n",
       "            background-color:  #455cce;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow4_col4 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow4_col5 {\n",
       "            background-color:  #3f53c6;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow4_col6 {\n",
       "            background-color:  #3f53c6;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow4_col7 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow5_col0 {\n",
       "            background-color:  #4358cb;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow5_col1 {\n",
       "            background-color:  #3d50c3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow5_col2 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow5_col3 {\n",
       "            background-color:  #4358cb;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow5_col4 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow5_col5 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow5_col6 {\n",
       "            background-color:  #3f53c6;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow5_col7 {\n",
       "            background-color:  #3f53c6;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow6_col0 {\n",
       "            background-color:  #3f53c6;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow6_col1 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow6_col2 {\n",
       "            background-color:  #3d50c3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow6_col3 {\n",
       "            background-color:  #3d50c3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow6_col4 {\n",
       "            background-color:  #3d50c3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow6_col5 {\n",
       "            background-color:  #4358cb;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow6_col6 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow6_col7 {\n",
       "            background-color:  #4358cb;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow7_col0 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow7_col1 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow7_col2 {\n",
       "            background-color:  #4b64d5;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow7_col3 {\n",
       "            background-color:  #4358cb;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow7_col4 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow7_col5 {\n",
       "            background-color:  #455cce;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow7_col6 {\n",
       "            background-color:  #455cce;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_df4c9a90_5e38_11ea_af85_8623b1190f1crow7_col7 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }</style><table id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1c\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Lag1</th>        <th class=\"col_heading level0 col1\" >Year</th>        <th class=\"col_heading level0 col2\" >Volume</th>        <th class=\"col_heading level0 col3\" >Lag2</th>        <th class=\"col_heading level0 col4\" >Lag5</th>        <th class=\"col_heading level0 col5\" >Lag4</th>        <th class=\"col_heading level0 col6\" >Lag3</th>        <th class=\"col_heading level0 col7\" >Today</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1clevel0_row0\" class=\"row_heading level0 row0\" >Lag1</th>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow0_col0\" class=\"data row0 col0\" >1.00</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow0_col1\" class=\"data row0 col1\" >0.03</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow0_col2\" class=\"data row0 col2\" >0.04</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow0_col3\" class=\"data row0 col3\" >-0.03</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow0_col4\" class=\"data row0 col4\" >-0.01</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow0_col5\" class=\"data row0 col5\" >-0.00</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow0_col6\" class=\"data row0 col6\" >-0.01</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow0_col7\" class=\"data row0 col7\" >-0.03</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1clevel0_row1\" class=\"row_heading level0 row1\" >Year</th>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow1_col0\" class=\"data row1 col0\" >0.03</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow1_col1\" class=\"data row1 col1\" >1.00</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow1_col2\" class=\"data row1 col2\" >0.54</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow1_col3\" class=\"data row1 col3\" >0.03</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow1_col4\" class=\"data row1 col4\" >0.03</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow1_col5\" class=\"data row1 col5\" >0.04</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow1_col6\" class=\"data row1 col6\" >0.03</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow1_col7\" class=\"data row1 col7\" >0.03</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1clevel0_row2\" class=\"row_heading level0 row2\" >Volume</th>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow2_col0\" class=\"data row2 col0\" >0.04</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow2_col1\" class=\"data row2 col1\" >0.54</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow2_col2\" class=\"data row2 col2\" >1.00</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow2_col3\" class=\"data row2 col3\" >-0.04</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow2_col4\" class=\"data row2 col4\" >-0.02</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow2_col5\" class=\"data row2 col5\" >-0.05</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow2_col6\" class=\"data row2 col6\" >-0.04</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow2_col7\" class=\"data row2 col7\" >0.01</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1clevel0_row3\" class=\"row_heading level0 row3\" >Lag2</th>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow3_col0\" class=\"data row3 col0\" >-0.03</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow3_col1\" class=\"data row3 col1\" >0.03</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow3_col2\" class=\"data row3 col2\" >-0.04</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow3_col3\" class=\"data row3 col3\" >1.00</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow3_col4\" class=\"data row3 col4\" >-0.00</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow3_col5\" class=\"data row3 col5\" >-0.01</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow3_col6\" class=\"data row3 col6\" >-0.03</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow3_col7\" class=\"data row3 col7\" >-0.01</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1clevel0_row4\" class=\"row_heading level0 row4\" >Lag5</th>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow4_col0\" class=\"data row4 col0\" >-0.01</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow4_col1\" class=\"data row4 col1\" >0.03</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow4_col2\" class=\"data row4 col2\" >-0.02</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow4_col3\" class=\"data row4 col3\" >-0.00</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow4_col4\" class=\"data row4 col4\" >1.00</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow4_col5\" class=\"data row4 col5\" >-0.03</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow4_col6\" class=\"data row4 col6\" >-0.02</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow4_col7\" class=\"data row4 col7\" >-0.03</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1clevel0_row5\" class=\"row_heading level0 row5\" >Lag4</th>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow5_col0\" class=\"data row5 col0\" >-0.00</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow5_col1\" class=\"data row5 col1\" >0.04</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow5_col2\" class=\"data row5 col2\" >-0.05</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow5_col3\" class=\"data row5 col3\" >-0.01</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow5_col4\" class=\"data row5 col4\" >-0.03</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow5_col5\" class=\"data row5 col5\" >1.00</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow5_col6\" class=\"data row5 col6\" >-0.02</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow5_col7\" class=\"data row5 col7\" >-0.01</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1clevel0_row6\" class=\"row_heading level0 row6\" >Lag3</th>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow6_col0\" class=\"data row6 col0\" >-0.01</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow6_col1\" class=\"data row6 col1\" >0.03</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow6_col2\" class=\"data row6 col2\" >-0.04</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow6_col3\" class=\"data row6 col3\" >-0.03</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow6_col4\" class=\"data row6 col4\" >-0.02</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow6_col5\" class=\"data row6 col5\" >-0.02</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow6_col6\" class=\"data row6 col6\" >1.00</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow6_col7\" class=\"data row6 col7\" >-0.00</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1clevel0_row7\" class=\"row_heading level0 row7\" >Today</th>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow7_col0\" class=\"data row7 col0\" >-0.03</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow7_col1\" class=\"data row7 col1\" >0.03</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow7_col2\" class=\"data row7 col2\" >0.01</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow7_col3\" class=\"data row7 col3\" >-0.01</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow7_col4\" class=\"data row7 col4\" >-0.03</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow7_col5\" class=\"data row7 col5\" >-0.01</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow7_col6\" class=\"data row7 col6\" >-0.00</td>\n",
       "                        <td id=\"T_df4c9a90_5e38_11ea_af85_8623b1190f1crow7_col7\" class=\"data row7 col7\" >1.00</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17b6744f640>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = df[['Lag1', 'Year', 'Volume', 'Lag2', 'Lag5', 'Lag4', 'Lag3', 'Today']].corr().round(2)\n",
    "corr.style.background_gradient(cmap='coolwarm').set_precision(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Interpretation</h1>\n",
    "<h2>Correlation \\$r and \\$p and heatmap</h2>\n",
    "\n",
    "The first table prints the correlation coefficients. The coefficient is calculated as a strong possible correlation (close to number 1) and strong negative correlation (close to number - 1). Positive correlation means that as one of the numbers increases, the second number will increase as well. Negative correlation means that as one number increases, the other will decrease.  \n",
    "\n",
    "Only features Volume with Year are strongly correlated and as if one of the numbers goes up the other goes up as well (as they are closer to 1). The opposite, there seems to be only little correlation between today's returns and previous days returns.  \n",
    "\n",
    "The second table prints the table of p - values corresponding to the significance levels of the correlations. In general the p - value evaluates how well the data rejects the null hypothesis, which shows whether a predictor is statistically significant. The cutoff for specifying the significance is known as the alpha value, which is most commonly set to 0.05. Thus, if the p - value is less than the 0.05 then the null hypothesis is rejected. As can be see from the results above the p-value of only Year and Volume is 0, which is less than the significance level 0.05. The conclusion is that Year and Volume are significantly correlated with a correlation coefficient of 0.54 and p-value of 0.    \n",
    "\n",
    "Lastly the table is printed in colors as a heatmap. In the generated colored heatmap, negative correlations are in blue and positive ones in red color. If there is no correlation between two variables, meaning when the correlation is close to 0, then the color is grey. Thus with the heatmap, we can see again that Year and Volume are correlated. The heatmap visualization helps to identify the correlations faster, however the explanation for the numbers is the same as the explanation for the correlation coefficient table above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0.5, 'Volume, the number of shares traded on the previous day, in billions'),\n",
       " Text(0.5, 0, 'Year')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.regplot(x = \"Year\", y = \"Volume\", \n",
    "            data=df, \n",
    "            marker='o', \n",
    "            color='black', \n",
    "            scatter_kws={'s':5})\n",
    "ax.set(xlabel='Year', ylabel='Volume, the number of shares traded on the previous day, in billions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Interpretation</h1>\n",
    "  \n",
    "By plotting Year with Volume it is visible that Volume is increasing over time. More specifically, starting from 2001 the average number of shares traded daily increases until 2005."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Generalized Linear Model Regression Results                           \n",
      "================================================================================================\n",
      "Dep. Variable:     ['Direction[Down]', 'Direction[Up]']   No. Observations:                 1250\n",
      "Model:                                              GLM   Df Residuals:                     1243\n",
      "Model Family:                                  Binomial   Df Model:                            6\n",
      "Link Function:                                    logit   Scale:                          1.0000\n",
      "Method:                                            IRLS   Log-Likelihood:                -863.79\n",
      "Date:                                  Wed, 04 Mar 2020   Deviance:                       1727.6\n",
      "Time:                                          18:11:20   Pearson chi2:                 1.25e+03\n",
      "No. Iterations:                                       4                                         \n",
      "Covariance Type:                              nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.1260      0.241      0.523      0.601      -0.346       0.598\n",
      "Lag1           0.0731      0.050      1.457      0.145      -0.025       0.171\n",
      "Lag2           0.0423      0.050      0.845      0.398      -0.056       0.140\n",
      "Lag3          -0.0111      0.050     -0.222      0.824      -0.109       0.087\n",
      "Lag4          -0.0094      0.050     -0.187      0.851      -0.107       0.089\n",
      "Lag5          -0.0103      0.050     -0.208      0.835      -0.107       0.087\n",
      "Volume        -0.1354      0.158     -0.855      0.392      -0.446       0.175\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "model = sm.formula.glm('Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume ',\n",
    "                       family=sm.families.Binomial(), data=df)\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Interpretation</h1>\n",
    "\n",
    "The smallest p-value associated with Lag1, and the **positive** coefficient means that if hte market had a positive return the previous day, it is likely to go up today again. But since the p-value of 0.145 is still > 0.05 we can not reject the null hypothesis and can conclude that there is no clear relation between Lag1 and Direction. For all other p-values it is similar since all of them are > 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49291587 0.51853212 0.51886117 0.48477764 0.48921884 0.49304354\n",
      " 0.50734913 0.49077084 0.48238647 0.51116222]\n"
     ]
    }
   ],
   "source": [
    "predictions = result.predict()\n",
    "print(predictions[0:10]) #1:10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependent variables:\n",
      "['Direction[Down]', 'Direction[Up]']\n",
      "\n",
      " Assigned dummy variables:\n",
      "[['Up' 0.0]\n",
      " ['Up' 0.0]\n",
      " ['Down' 1.0]\n",
      " ...\n",
      " ['Up' 0.0]\n",
      " ['Down' 1.0]\n",
      " ['Down' 1.0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Dependent variables:\")\n",
    "print(result.model.endog_names)\n",
    "print(\"\\n Assigned dummy variables:\")\n",
    "print(np.column_stack((df[[\"Direction\"]], \n",
    "                       result.model.endog)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[145 457]\n",
      " [141 507]]\n",
      "Accuracy Score: 0.5216\n"
     ]
    }
   ],
   "source": [
    "predictions_nominal = [ \"Up\" if x < 0.5 else \"Down\" for x in predictions]\n",
    "print(confusion_matrix(df[\"Direction\"], \n",
    "                       predictions_nominal))\n",
    "print('Accuracy Score:',accuracy_score(df[\"Direction\"], predictions_nominal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Interpretation</h1>\n",
    "\n",
    "\n",
    "Up (0.0) and Down (1.0) have assigned dummy variables to them, as can be seen in the matrix above. The off - diagonal elements present the incorrect predictions (457 and 141). The confusion matrix presents also diagonal elements, which indicate the correct predictions (145 + 507 = 652 / 1250 = 0.5216)  So, from this calculation we get the mean or accuracy score to compute the fraction of days for which the prediction was correct. In this example the prediction was accurate or correct for predicting the movement of the market 52.2\\% of the time. With this value we also get the training error rate, which is in this case 100 - 52.2 = 47.8\\%. However, the training error rate tends to underestimate the test error rate (as stated in the course literature book). Thus, further steps will be taken in the following parts to assess the accuracy of the logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[114 488]\n",
      " [102 546]]\n",
      "Accuracy Score: 0.528\n"
     ]
    }
   ],
   "source": [
    "model = sm.formula.glm('Direction ~ Lag1 + Lag2',\n",
    "                       family=sm.families.Binomial(), data=df)\n",
    "result = model.fit()\n",
    "predictions = result.predict()\n",
    "predictions_nominal = [ \"Up\" if x < 0.5 else \"Down\" for x in predictions]\n",
    "print(confusion_matrix(df[\"Direction\"], \n",
    "                       predictions_nominal))\n",
    "print('Accuracy Score:',accuracy_score(df[\"Direction\"], predictions_nominal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Interpretation</h1>\n",
    "\n",
    "This diagonals and off - diagonals present again the correct and incorrect predictions. So, in this example where the subset of Lag1 + Lag2 predictors were only shown, the correct predictions are 114 + 546 = 660 / 1250 = 0.528 . Thus, compared to the previous example, where now only Lag1 + Lag2 are choosen as predictors, the prediction was accurate / correct for predicting the movement of the market 52.8\\% of the time. This is slightly better than when all predictors were choosen in the previous example. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Performing an LDA</h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior probabilities of groups: \n",
      "[0.4816 0.5184]\n",
      "\n",
      " Group means: \n",
      "[[ 0.05068605  0.03229734]\n",
      " [-0.03969136 -0.02244444]]\n",
      "\n",
      " Coefficients of linear discriminants: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LD1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lag1</th>\n",
       "      <td>-0.756761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag2</th>\n",
       "      <td>-0.470787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           LD1\n",
       "Lag1 -0.756761\n",
       "Lag2 -0.470787"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = df[['Lag1','Lag2']]\n",
    "y_train = df['Direction']\n",
    "\n",
    "X_test = df[['Lag1','Lag2']]\n",
    "y_test = df['Direction']\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "model = lda.fit(X_train, y_train)\n",
    "\n",
    "print('Prior probabilities of groups: ')\n",
    "print(model.priors_)\n",
    "print('\\n Group means: ')\n",
    "print(model.means_)\n",
    "print('\\n Coefficients of linear discriminants: ')\n",
    "\n",
    "def pretty_scalings(lda, X, out=False):\n",
    "    ret = pd.DataFrame(lda.scalings_, index=X.columns, columns=[\"LD\"+str(i+1) for i in range(lda.scalings_.shape[1])])\n",
    "    if out:\n",
    "     #  print(\"Coefficients of linear discriminants:\")\n",
    "        display(ret)\n",
    "    return ret\n",
    "\n",
    "pretty_scalings_ = pretty_scalings(model, X_train, out=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  3.,   5.,  12.,  20.,  72., 182., 375., 350., 158.,  40.,  19.,\n",
       "         10.,   2.,   2.]),\n",
       " array([-7.126     , -6.08821429, -5.05042857, -4.01264286, -2.97485714,\n",
       "        -1.93707143, -0.89928571,  0.1385    ,  1.17628571,  2.21407143,\n",
       "         3.25185714,  4.28964286,  5.32742857,  6.36521429,  7.403     ]),\n",
       " <a list of 14 Patch objects>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create new column and use that for histogram, to have even an overlapping histogram\n",
    "df[\"lag1_lag2\"] = df['Lag1']+df['Lag2'] \n",
    "dir_up = df[df['Direction']==\"Up\"]\n",
    "dir_down = df[df['Direction']==\"Down\"]\n",
    "\n",
    "plt.hist(df[\"lag1_lag2\"],\n",
    "        facecolor='orangered',\n",
    "        edgecolor='maroon',\n",
    "        bins=14)\n",
    "\n",
    "# *****Another failed attempt*******\n",
    "# import matplotlib.pyplot as plt\n",
    "# y = df[\"lag1_lag2\"]\n",
    "# x = df['Direction']\n",
    "# plt.bar(x,y) # A bar chart\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Interpretation</h1>\n",
    "\n",
    "Prior probabilities of groups shows that 48.2\\% of the trained observations correspond to the days when the market went down and 51.8\\% to those when the market went up.  \n",
    "The group means are the average of each predictor within each class. The results here indicate that the returns for the previous two days tend to be positive when the market declines and negative when the market increases.  \n",
    "Coefficients of linear discriminants gives in this example the linear combination of Lag1 and Lag2 that are used to form the LDA decision rule. Thus, if - 0.757 x Lag1 - 0.471 x Lag2 is large, the the prediction from LDA would be that the market would increase, and on the other hand if it is small, then the LDA prediction would say a market decline.  \n",
    "The failed attempt at the histogram:  What it should really print is actually the trained model of x = Lag1 + Lag2 and y - Direction (thus Direction is either Up or Down)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Using the LDA model </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[114 102]\n",
      " [488 546]]\n",
      "\n",
      " Accuracy Score: 0.528\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "#print(np.unique(pred, return_counts = True))\n",
    "print(confusion_matrix(pred, y_test))\n",
    "print('\\n Accuracy Score:',accuracy_score(df[\"Direction\"], pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Interpretation</h1>\n",
    "\n",
    "\n",
    "This diagonals and off - diagonals present again the correct and incorrect predictions. So, in this example where the subset of Lag1 + Lag2 predictors were only shown, the correct predictions are 114 + 546 = 660 / 1250 = 0.528 . Thus, compared to the logistic regression, where the predictors were the same, it is visible that the confusion matrix and accuracy score are the same too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Performing an QDA</h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior probabilities of groups: \n",
      "[0.4816 0.5184]\n",
      "\n",
      " Group means: \n",
      "[[ 0.05068605  0.03229734]\n",
      " [-0.03969136 -0.02244444]]\n"
     ]
    }
   ],
   "source": [
    "X_train = df[['Lag1','Lag2']]\n",
    "y_train = df['Direction']\n",
    "\n",
    "X_test = df[['Lag1','Lag2']]\n",
    "y_test = df['Direction']\n",
    "\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "model = qda.fit(X_train, y_train)\n",
    "\n",
    "print('Prior probabilities of groups: ')\n",
    "print(model.priors_)\n",
    "print('\\n Group means: ')\n",
    "print(model.means_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Interpretation</h1>\n",
    "\n",
    "The results for prior probabilities of groups and for group means are the same as when performed with LDA, since the groupps are the same (thus, same interpretation applies). However, this time, there are no linear discrimintants. That is simply because QDA performs quadratic function of the predictors and not linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[109  94]\n",
      " [493 554]]\n",
      "\n",
      " Accuracy Score: 0.5304\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "print(confusion_matrix(pred, y_test))\n",
    "print('\\n Accuracy Score:',accuracy_score(df[\"Direction\"], pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Interpretation</h1>\n",
    "\n",
    "This diagonals and off - diagonals present again the correct and incorrect predictions. So, the correct predictions are 109 + 554 = 663 / 1250 = 0.530 . Thus, compared to the logistic regression, and LDA, where all models had same predictors, it is visible that the confusion matrix and accuracy score have best results when performing QDA. The accuracy score is now 53.0\\%  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Using K-Nearest Neighbors Clustering</h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(252, 9)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# objects before 2005 set to true\n",
    "train = df[df['Year']<2005]\n",
    "train.shape #998 \n",
    "\n",
    "# set to !train, thus to false\n",
    "not_train = df[df['Year']==2005]\n",
    "not_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df[df['Year']<2005][['Lag1','Lag2']]\n",
    "y_train = df[df['Year']<2005]['Direction']\n",
    "\n",
    "X_test = df[df['Year']==2005][['Lag1','Lag2']]\n",
    "y_test = df[df['Year']==2005]['Direction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors = 1)\n",
    "pred = knn.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43 58]\n",
      " [68 83]]\n",
      "\n",
      " Accuracy Score: 0.5\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, pred).T)\n",
    "#print(classification_report(y_test, pred, digits=3))\n",
    "print('\\n Accuracy Score:',accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[48 55]\n",
      " [63 86]]\n",
      "\n",
      " Accuracy Score: 0.5317460317460317\n"
     ]
    }
   ],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "model = knn.fit(X_train, y_train)\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "print(confusion_matrix(y_test, pred).T)\n",
    "#print(classification_report(y_test, pred, digits=3))\n",
    "print('\\n Accuracy Score:',accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Interpretation</h1>\n",
    "\n",
    "Again the aim was to predict Direction using percentage returns from Lag1 and Lag2 (the previous two days). To train the model, only the observations from years 2001 until 2004 were chosen. The year 2005 is used to perform the testing on. The confusion matrix and an accuracy score are computed for both, when K = 1 and when K = 3. K is the number of nearest neighbors used by the classifier.  \n",
    "**K = 1** This diagonals and off - diagonals present again the correct and incorrect predictions. So, the correct predictions are 43 + 83 = 126 / 252 = 0.5 . The accuracy score is now 50.0\\%  \n",
    "**K = 3** This diagonals and off - diagonals present again the correct and incorrect predictions. So, the correct predictions are 48 + 86 = 134 / 252 = 0.532 . The accuracy score is now 53.2\\%.  \n",
    "Thus, when taking 3 nearest neighbors, the accuracy score improves slightly.  \n",
    "\n",
    "Overall, it seems that KNN (3 nearest neighbors) with an accuracy score of 53.2\\% followed by QDA with 53.04\\% seem to provide best accuracy scores for this data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
